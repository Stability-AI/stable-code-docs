"use strict";(self.webpackChunkstable_code=self.webpackChunkstable_code||[]).push([[727],{1208:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>c});var o=t(4848),a=t(8453);const r={sidebar_position:3,title:"Repositories QA"},s="Repositories QA",i={id:"tutorial-usage/repository_qa",title:"Repositories QA",description:"In this tutorial, we will show you how you can create a simple program",source:"@site/docs/tutorial-usage/repository_qa.mdx",sourceDirName:"tutorial-usage",slug:"/tutorial-usage/repository_qa",permalink:"/docs/tutorial-usage/repository_qa",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,title:"Repositories QA"},sidebar:"tutorialSidebar",previous:{title:"Stable Code on Ollama",permalink:"/docs/tutorial-usage/ollama"},next:{title:"Tutorial - Finetuning Stable Code",permalink:"/docs/category/tutorial---finetuning-stable-code"}},l={},c=[];function h(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",img:"img",p:"p",pre:"pre",strong:"strong",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"repositories-qa",children:"Repositories QA"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://colab.research.google.com/github/Stability-AI/stable-code-docs/blob/main/docs/tutorial-usage/repository_qa.ipynb",children:(0,o.jsx)(n.img,{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:""})})}),"\n",(0,o.jsx)(n.p,{children:"In this tutorial, we will show you how you can create a simple program\nusing Stable Code Instruct and Langchain to ask questions about a\nrepository."}),"\n",(0,o.jsxs)(n.blockquote,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Note"}),": This tutorial has been adapted from Langchain\u2019s ",(0,o.jsx)(n.a,{href:"https://python.langchain.com/docs/use_cases/code_understanding",children:"official\ntutorial"}),"."]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"First, let\u2019s go ahead and install our dependencies."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"%pip install -qU tree_sitter tree_sitter_languages sentence_transformers langchain langchain-community faiss-cpu GitPython\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Let\u2019s first go ahead and clone a repository to work with. We\u2019ll use the\n",(0,o.jsx)(n.code,{children:"langchain"})," repository as an example and GitPython to clone it."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from git import Repo\n\nrepo_path = "/content/langchain"\nrepo = Repo.clone_from("https://github.com/langchain-ai/langchain", to_path=repo_path)\n'})}),"\n",(0,o.jsx)(n.p,{children:"Now that we have the repository, we need to get it into a form that we\ncan easily ask questions about. To do this we need to create a vector\ndatabase that will be used to match questions to the code in the\nrepository."}),"\n",(0,o.jsx)(n.p,{children:"We will be using tree-sitter for parsing the code in our repository to\nchunks that we will retrieve when we ask questions."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from langchain_community.document_loaders.generic import GenericLoader\nfrom langchain_community.document_loaders.parsers import LanguageParser\nfrom langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n\nloader = GenericLoader.from_filesystem(\n    repo_path,\n    glob="*",\n    suffixes=[".py"],\n    parser=LanguageParser(),\n)\ndocs = loader.load()\n\npython_splitter = RecursiveCharacterTextSplitter.from_language(\n    language=Language.PYTHON, chunk_size=2000, chunk_overlap=200 # Tune these parameters to your liking\n)\ntexts = python_splitter.split_documents(docs)\nlen(texts)\n'})}),"\n",(0,o.jsx)(n.p,{children:"With the chunks of code in hand, we can now vectorize them and store\nthem in a database. For vectorization, we will use the awesome MiniLM\nmodel from the sentence-tranformer library. And for the database, we\nwill use Faiss."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from langchain_community.vectorstores import FAISS\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\ndb = FAISS.from_documents(texts, HuggingFaceEmbeddings())\nretriever = db.as_retriever(\n    search_type="mmr",  # Also test "similarity"\n    search_kwargs={"k": 8},\n)\n'})}),"\n",(0,o.jsx)(n.p,{children:"We will use Ollama to serve our model and answer questions about the\nrepository. Therefore, we need to install it. You can install it by\nrunning the following if you are on linux or using colab:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"!curl -fsSL https://ollama.com/install.sh | sh\n"})}),"\n",(0,o.jsx)(n.p,{children:"Next, we need to setup the ollama server to run in the background:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"!ollama serve\n"})}),"\n",(0,o.jsx)(n.p,{children:"Finally, we can chat with our repository."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Note:"})," The first time running this will take a while since you need\nto download the necessary model weights to run the model."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from langchain.chains import ConversationalRetrievalChain\nfrom langchain.memory import ConversationSummaryMemory\nfrom langchain_community.chat_models import ChatOllama\n\nllm = ChatOllama(model="stable-code:instruct")\nmemory = ConversationSummaryMemory(\n    llm=llm, memory_key="chat_history", return_messages=True\n)\nqa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)\n\nquestion = "How can I initialize a ReAct agent?"\nresult = qa(question)\nresult["answer"]\n'})})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>i});var o=t(6540);const a={},r=o.createContext(a);function s(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);